Projeto II --- Operações sobre conjuntos (sets)

# Introdução

Conjuntos podem ser compreeendidos como uma coleção abstrata de elementos
que não possui uma ordem específica e permite operações como inserção,
remoção, união e interseção, bem como verificação de pertencimento. Nesse
projeto foi implementado um conjunto capaz de guardar como elementos números
inteiros, sendo possível ao usuário escolher uma dentre duas estruturas de 
dados para servir de implementação do conjunto. 

# Implementação

Para representar os conjuntos, decidimos usar árvores binárias de busca (ABBs)
do tipo AVL e LLRB (left-leaning red-black tree). Dessa forma, as árvores se
mantém balanceadas de acordo com as regras de balanceamento para cada tipo de
árvore, garantido que a altura das árvores será sempre limitada superiormente
por um certo fator (um múltiplo constante de log n, sendo n a quantidade de 
elementos), permitindo a implementação das operações de modo eficiente.

Para manter o balanceamento das árvores AVL, as operações rotação simples 
para a esquerda/direita e rotação dupla direita-esquerda/esquerda-direita
são utilizadas. Já para a LLRB, as operações usadas são rotação para a 
esquerda/direita e inversão de cores (na inserção e remoção), bem como 
propagação de cor para a esquerda/direita (apenas na remoção).

Além das operações mais convencionais em ABBs, também foram implementadas
as operações juntar/catenar (*join*/*catenate*) e separar (*split*), essas
duas apenas para a árvore AVL, visto que adaptar a implementação abordada 
para a LLRB seria um processo não trivial, envolvendo decisões de projeto
mais complexas, como decidir se um nó deveria ou não armazenar sua altura
negra. As operações mencionadas permitem a implementação da operação união
de modo mais eficiente comparado à implementação "ingênua" de união entre
ABBs[1][2].

Um detalhe importante para a nossa implementação é que os valores armazenados
em cada nó da árvore correspondem diretamente às chaves usadas para ordenação
da ABB. Caso não houvesse essa correspondência, seria necessário adaptar os
algoritmos *join* e *split* apresentados. Além disso, nossa implementação
assume e mantém a invariante de unicidade das chaves.

# Análise de Complexidade

## Árvores binárias de busca balanceadas (ABBbal)

Árvores AVL e rubro-negras são árvores binárias de busca que se mantém 
balanceadas de acordo com determinadas regras, logo, a complexidade
de tempo para a operação busca será a mesma em ambas. A operação busca é
usada para implementar verificação de pertencimento em um conjunto. Uma 
implementação convencional, recursiva, de busca em ABB consiste de uma
verificação para tratar o caso onde se chega a um nó nulo ou um nó com o valor
desejado. Caso nenhum desses dois casos seja atingido, a busca prossegue pela
esquerda ou pela direita. No pior caso, a busca terminará em um nó nulo, sem
encontrar o valor desejado. Portanto, podemos montar a seguinte relação de 
recorrência para descrever a complexidade dessa operação:

                           T(n) = T(n/2) + O(1)

Pelo Teorema Mestre, sabemos que T(n) = O(log n).

Além disso, as operações inserção e remoção também podem ser analisadas em suas
formas mais simples, apenas para ABBs, para que depois sejam abordadas em mais
detalhes considerando as operações de balanceamento das árvores AVL e LLRB.

A operação inserção em uma ABB consiste em realizar uma busca pelo valor a ser
inserido. Caso o valor já exista na árvore, não há nada a ser feito. Caso não 
exista, deve ser inserido na posição atual. A inserção é, novamente, uma simples
manipulação de ponteiros; se o local de inserção já for conhecido de antemão,
a inserção pode ser realizada em O(1). Portanto, a inserção tem complexidade
de tempo de O(log n).

Por sua vez, a operação remoção consiste em buscar o valor a ser removido. Se o
valor não for encontrado, não há nada a ser feito (caso i). Se o nó correspondente 
tiver um filho, esse nó é removido da árvore e substituído por seu filho (caso ii).
Se tiver dois filhos, devemos substituí-lo por um sucessor na árvore, seja esse o
menor da subárvore direita ou o maior da subárvore esquerda (caso iii).

Nos casos i. e ii., as operações de remoção têm complexidade de tempo constante 
ao se fixar a posição de remoção. No caso iii., podemos notar que a substituição
pelo sucessor se dá também em O(1) e que a soma da profundidade do nó a ser removido
com a altura do seu sucessor na subárvore escolhida deve ser igual à altura da árvore
original. Portanto, em todos os casos, a complexidade da operação remoção é O(log n).

Também adicionamos a operação clonar, que clona uma ABB em O(n), recursivamente, 
apresentando a seguinte relação de recorrência:

                            T(n) = 2T(n/2) + O(1)

A operação interseção entre conjuntos foi implementada de forma "ingênua", pois 
essa forma é mais eficiente que o método abordado em [1] quando devemos preservar 
os conjuntos originais: sejam as árvores originais de tamanho n e m, com n > m.
Percorremos a árvore de menor tamanho, verificando se cada elemento existe na outra
árvore e, se existir, o inserimos na árvore que irá guardar o resultado da
interseção. Evidentemente, a complexidade de tempo dessa operação é 
O(m * (log(n) + log(m))) = O(m * log(n * m)) no pior caso, onde o termo m 
corresponde ao percurso da árvore menor, log(n) à busca na árvore maior e 
log(m) à inserção na árvore resultante.

A operação união possui uma implementação otimizada para duas árvores do tipo AVL,
como mencionado a seguir. No entanto, se as duas árvores envolvidas na união não
forem ambas do tipo AVL, uma implementação "ingênua" é usada: a árvore de maior
tamanho é clonada e a árvore de menor tamanho é percorrida, tendo seus elementos
inseridos na árvore resultante. A complexidade de tempo dessa operação é da ordem 
de O(n + m * log(n + m)). 

## Árvores AVL

A operação rotação esquerda (`avl_rotate_left`) apresenta complexidade de 
tempo da ordem de O(1), uma vez que é composta de apenas duas atribuições simples
de ponteiros e mais duas atribuições para atualizar a altura dos nós envolvidos
na rotação. A operação rotação direita é análoga (simétrica), enquanto as rotações
duplas são apenas duas rotações simples aplicadas em sequência. Portanto, a
complexidade de tempo de todas essas operações é O(1).

A operação inserção em AVL consiste de inserção em uma ABB convencional, porém com
cálculo da altura e do fator de balanceamento do nó atual, seguido de rotações, na
volta da recursão, se for necessário, para corrigir casos de desbalanceamento.
As verificações e cálculos realizados são efetuados em O(1), logo a complexidade
de inserção em árvores AVL é O(log n).

A remoção em árvores AVL é idêntica à remoção em ABBs, adotando o mesmo procedimento 
usado na inserção para corrigir desbalanceamentos na volta da recursão. 
Logo, a sua complexidade é O(log n).

Além disso, mencionaremos as operações *join* e *split*, que foram implementadas para
a árvore AVL. Essas operações permitem a implementação da operação união entre duas 
árvores em O(n) em vez de O(n * log(n)). Ao passo que [1] encontra um limitante 
superior ainda melhor, não iremos explorar essa possibilidade, uma vez que as técnicas
usadas para análise de complexidade necessárias para obtenção desses limitantes melhores 
são muito complexas para serem abordadas nesse relatório. Além disso, outros fatores
envolvendo decisões de projeto impedem esses limitantes superiores melhores de serem
úteis na prática: como as operações *join* e *split* são destrutivas, devemos clonar as
árvores antes de aplicar essas operações. Também devemos percorrer a árvore após realizar
uma união para calcular seu tamanho. Dessa forma, a melhor complexidade que poderia ser 
obtida é O(n).

A operação *join* é definida da seguinte forma: sejam T1 e T2 ABBs e k uma chave tal que
T1 < k < T2. Ou seja, todos os valores em T1 são menores do que k e todos os valores em T2
são maiores do que k. join(T1, k, T2) retorna uma árvore T = T1 ∪ {k} ∪ T2. Sua implementação
é trivial em uma ABB convencional, porém se torna um pouco mais complicada quando se deseja 
que a árvore resultante se mantenha balanceada. A ideia por trás é percorrer a árvore de maior
altura dentre T1 e T2, na direção em que as chaves se "aproximam" de k. Ao encontrar um nó, 
digamos, v, nessa árvore, que possui altura h + 1, onde h é a altura da menor árvore, podemos 
inserir um nó "k" como filho desse nó encontrado, tornando o filho original de v um dos filhos 
de k e a raiz da outra árvore o outro filho de k. Após essa inserção, ajustes necessários para 
manter o balanceamento da árvore são feitos na volta da recursão, em O(1) cada um.

Uma vez que a operação *join* foi implementada recursivamente, podemos montar a seguinte 
relação de recorrência, considerando que as duas árvores envolvidas têm tamanho n e que o
caso base se daria, no pior caso, após ter percorrido uma altura proporcional à altura da 
maior árvore para simplificar a análise:

                                    T(n) = T(n/2) + O(1)

Novamente, obtemos pelo Teorema Mestre que a complexidade de tempo da operação *join* é O(log n).

Por sua vez, a operação *split* é definida da seguinte forma: split(T, k) retorna duas árvores, 
T1 e T2, onde T1 < k < T2, além de indicar se k estava presente em T ou não. A ideia por trás é
realizar uma busca de k em T, recursivamente. Na volta da recursão, teremos o resultado da 
operação *split* no filho do nó atual na direção da busca. Digamos que esse resultado é composto
de árvores T_a e T_b tais que T_a < k < T_b, de forma que o filho do nó atual que não foi analisado 
corresponde à raiz de uma árvore T_c e que o valor do nó atual é dado por A. Se a busca seguiu 
pela esquerda, então T_c > k, logo devemos realizar a operação join(T_b, A, T_c), guardando o 
resultado dessa operação como o novo T_b. Analogamente, se a busca seguiu pela direita, então 
T_c < k, logo devemos atualizar T_a com o resultado de join(T_c, A, T_a).
O caso base da operação *split* corresponde a um nó nulo ou nó com o valor k.

Dada a implementação da operação *split*, é possível montar a seguinte relação de recorrência:

                                  T(n) = T(n/2) + O(log n)

Essa relação não pode ser solucionada usando o Teorema Mestre, no entanto, é possível solucioná-la
de forma aproximada pelo método da substituição, trocando O(log n) por log2(n): tome, por exemplo,
T(2^3) = T(2^2) + log2(2^3) = T(2) + log2(2^2) + log2(2^3) = T(1) + log2(2) + log2(2^2) + log2(2^3).
Assumindo que T(1) = 0, podemos deduzir que:

           T(n) = sum(i=1, log2(n), i) = (log2(n) * (log2(n) + 1)) / 2 = O((log n)^2)

Podemos verificar essa igualdade realizando a substituição na relação de recorrência, assumindo 
log na base 2:

 T(n) = log(n/2) * [log(n/2) + 1] / 2 + log(n) = [log(n/2)]^2 / 2  +  log(n/2) / 2  +  log(n)
      = (log(n) - log(2))^2 / 2  +  (log(n) - log(2)) / 2  +  log(n)
      = ([log(n)]^2 - 2log(n) + 1) / 2  +  (log(n) - 1) / 2  +  2log(n) / 2
      = ([log(n)]^2 + log(n)) / 2 
      = (log(n) * (log(n) + 1)) / 2

Portanto, a complexidade de tempo da operação *split* é da ordem de O((log n)^2).

Por sua vez, a operação união recebe duas ABBs arbitrárias, T1 e T2, e retorna T1 ∪ T2,
destruindo T1 e T2. A ideia por trás é aplicar a operação *split* em T1 sendo k dado
pelo valor da raiz de T2. Assim, obtemos duas árvores, T_a e T_b, sendo T_a os 
elementos de T1 menores que k e T_b os elementos de T1 maiores que k. Aplicamos então,
recursivamente, a união entre T_a e o filho esquerdo da raiz de T2, bem como a união
entre T_b e o filho direito de T2, obtendo, assim, duas árvores que podem ser juntadas
usando a operação *join*. Como não queremos que T1 e T2 sejam destruídas na implementação 
do conjunto, como já mencionado, devemos clonar as árvores antes de aplicar essa operação. 

O trabalho realizado pela operação união é proporcional a T(n), dada pela seguinte 
relação de recorrência, onde o primeiro termo corresponde às chamadas recursivas,
o segundo termo à operação *split* e o terceiro à operação *join*.

              T(n) = 2T(n/2) + O((log n)^2) + O(log n) = 2T(n/2) + O((log n)^2)

Essa relação de recorrência pode ser resolvida pelo Teorema Mestre, obtendo O(n) para
complexidade da operação união entre duas árvores AVL, sendo n o tamanho da maior árvore.
Portanto, levando em consideração o uso da operação clonar, que é O(n), é possível 
realizar união entre dois conjuntos em O(n).

## Árvores LLRB

A operação rotação esquerda em LLRBs também consiste de atribuições simples de ponteiros,
adicionalmente realizando atribuições para as cores dos nós para corrigir as cores após a
rotação. Esse procedimento é realizado em O(1). A rotação direita é análoga. A operação
inversão de cor consiste de três verificações e três atribuições simples, sendo também da
ordem de O(1).

A inserção em LLRBs é idêntica à inserção em ABBs, com a adição de três verificações
para corrigir casos que violem as regras de balanceamento da LLRB, portanto apresenta
a mesma complexidade de tempo. Por sua vez, a remoção possui verificações adicionais 
para o caso em que a busca prossegue para a direita ou para a esquerda, uma vez que é
necessário "propagar" as arestas vermelhas para o nó folha a ser removido. Essas 
verificações e ajustes, novamente, são da ordem de O(1).

## Detalhes

É importante ressaltar que há algumas diferenças mais sutis entre a árvore AVL e a LLRB,
que não são refletidas nas complexidades de tempo de suas operações: a altura máxima que
uma árvore AVL pode atingir é logφ(n) ≈ 1,44 * log2(n), enquanto a altura máxima para uma
árvore LLRB é 2 * log2(n). Ou seja, a árvore AVL é uma opção melhor que árvores RB para 
casos em que buscas são realizadas frequentemente.

# Referências

[1]: BLELLOCH, G. E.; FERIZOVIC, D.; YIHAN, S. Just Join for Parallel Ordered Sets.
Disponível em: https://www.cs.cmu.edu/~guyb/papers/BFS16.pdf

[2]: WEIN, R. Efficient Implementation of Red-Black Trees with Split and Catenate Operations.
Disponível em: https://web.archive.org/web/20120309154420/http://www.cs.tau.ac.il/~wein/publications/pdfs/rb_tree.pdf
